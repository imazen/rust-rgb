name: Test Downstream Compatibility

on:
  pull_request:
  push:
    tags:
      - 'v*'
  release:
    types: [published, created]

jobs:
  test-dependents:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
      issues: write
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Extract crate metadata
        id: metadata
        run: |
          # Get crate name from Cargo.toml
          CRATE_NAME=$(grep -m1 '^name = ' Cargo.toml | sed 's/name = "\(.*\)"/\1/')
          echo "crate-name=$CRATE_NAME" >> $GITHUB_OUTPUT
          
          # Get repository info from context
          echo "repo-name=${{ github.event.repository.name }}" >> $GITHUB_OUTPUT
          echo "repo-owner=${{ github.repository_owner }}" >> $GITHUB_OUTPUT
          echo "ref-name=${{ github.ref_name }}" >> $GITHUB_OUTPUT
          echo "event-name=${{ github.event_name }}" >> $GITHUB_OUTPUT
          
          # Determine what we're testing
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            TEST_TYPE="Pull Request #${{ github.event.pull_request.number }}"
            TEST_REF="${{ github.event.pull_request.head.sha }}"
          elif [[ "${{ github.event_name }}" == "release" ]]; then
            TEST_TYPE="Release ${{ github.event.release.tag_name }}"
            TEST_REF="${{ github.event.release.tag_name }}"
          elif [[ "${{ github.ref }}" == refs/tags/* ]]; then
            TEST_TYPE="Tag ${{ github.ref_name }}"
            TEST_REF="${{ github.ref_name }}"
          else
            TEST_TYPE="Push to ${{ github.ref_name }}"
            TEST_REF="${{ github.sha }}"
          fi
          
          echo "test-type=$TEST_TYPE" >> $GITHUB_OUTPUT
          echo "test-ref=$TEST_REF" >> $GITHUB_OUTPUT
          
          echo "Testing crate: $CRATE_NAME"
          echo "Test type: $TEST_TYPE"
          echo "Test ref: $TEST_REF"
      
      - name: Configure downstream crates
        id: config
        run: |
          # TODO: Replace this with your actual downstream dependents
          # You could also read this from a .github/downstream-crates.txt file
          CRATES="load_image,cavif,dssim,usc,okhsl,kapy,fecund_font_flounder,feather-ui,unitedservices_common"
          
          # Or read from a file if it exists
          if [ -f .github/downstream-crates.txt ]; then
            CRATES=$(cat .github/downstream-crates.txt | tr '\n' ',' | sed 's/,$//')
          fi
          
          echo "crates=$CRATES" >> $GITHUB_OUTPUT
          echo "Testing against: $CRATES"
      
      - name: Create test script
        run: |
          cat > test-all.sh <<'SCRIPT'
          #!/bin/bash
          set +e
          
          RED='\033[0;31m'
          GREEN='\033[0;32m'
          YELLOW='\033[1;33m'
          BLUE='\033[0;34m'
          MAGENTA='\033[0;35m'
          CYAN='\033[0;36m'
          NC='\033[0m'
          
          CRATE_NAME=$1
          CRATE_PATH=$2
          TEST_TYPE=$3
          TEST_REF=$4
          REPO_OWNER=$5
          REPO_NAME=$6
          
          IFS=',' read -ra CRATES <<< "$7"
          
          declare -A RESULTS
          declare -A DURATIONS
          declare -A ERRORS
          
          echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
          echo -e "${CYAN}â•‘${NC}  ${BLUE}Downstream Compatibility Test${NC}                         ${CYAN}â•‘${NC}"
          echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
          echo ""
          echo -e "${MAGENTA}Repository:${NC} ${REPO_OWNER}/${REPO_NAME}"
          echo -e "${MAGENTA}Crate:${NC} ${CRATE_NAME}"
          echo -e "${MAGENTA}Testing:${NC} ${TEST_TYPE}"
          echo -e "${MAGENTA}Ref:${NC} ${TEST_REF}"
          echo -e "${MAGENTA}Downstream crates:${NC} ${#CRATES[@]}"
          echo ""
          echo -e "${BLUE}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
          echo ""
          
          TOTAL_START=$(date +%s)
          
          for crate in "${CRATES[@]}"; do
            crate=$(echo "$crate" | xargs)  # Trim whitespace
            [ -z "$crate" ] && continue
            
            echo -e "${BLUE}[$(date +%H:%M:%S)] Testing ${crate}...${NC}"
            START=$(date +%s)
            
            # Clone the crate
            if cargo clone "$crate" 2>&1 | tee clone.log | grep -q "Downloaded"; then
              cd "$crate"
              
              # Add patch section to use our local version
              echo "" >> Cargo.toml
              echo "[patch.crates-io]" >> Cargo.toml
              echo "${CRATE_NAME} = { path = \"${CRATE_PATH}\" }" >> Cargo.toml
              
              # Try to build and test with timeout
              echo -e "  ${CYAN}Building...${NC}"
              if timeout 600 cargo test --quiet 2>&1 | tee ../test.log; then
                RESULTS[$crate]="âœ“"
                STATUS="PASSED"
                COLOR=$GREEN
                ERRORS[$crate]=""
              else
                EXIT_CODE=$?
                if [ $EXIT_CODE -eq 124 ]; then
                  RESULTS[$crate]="â±"
                  STATUS="TIMEOUT"
                  COLOR=$YELLOW
                  ERRORS[$crate]="Test exceeded 10 minute timeout"
                else
                  RESULTS[$crate]="âœ—"
                  STATUS="FAILED"
                  COLOR=$RED
                  # Capture last few lines of error
                  ERRORS[$crate]=$(tail -5 ../test.log | sed 's/^/    /')
                fi
              fi
              
              cd ..
              rm -f test.log clone.log
            else
              RESULTS[$crate]="âš "
              STATUS="SKIP"
              COLOR=$YELLOW
              ERRORS[$crate]="Failed to clone crate"
            fi
            
            END=$(date +%s)
            DURATIONS[$crate]=$((END - START))
            echo -e "  ${COLOR}${RESULTS[$crate]} ${STATUS}${NC} (${DURATIONS[$crate]}s)"
            
            # Show error if present and not too long
            if [ -n "${ERRORS[$crate]}" ] && [ "${#ERRORS[$crate]}" -lt 500 ]; then
              echo -e "${RED}${ERRORS[$crate]}${NC}"
            fi
            echo ""
          done
          
          TOTAL_END=$(date +%s)
          TOTAL_DURATION=$((TOTAL_END - TOTAL_START))
          
          # Summary
          echo -e "${BLUE}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
          echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
          echo -e "${CYAN}â•‘${NC}  ${BLUE}SUMMARY${NC}                                                ${CYAN}â•‘${NC}"
          echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
          echo ""
          
          PASSED=0; FAILED=0; TIMEOUT=0; SKIP=0
          
          for crate in "${CRATES[@]}"; do
            crate=$(echo "$crate" | xargs)
            [ -z "$crate" ] && continue
            
            case "${RESULTS[$crate]}" in
              "âœ“") 
                echo -e "${GREEN}âœ“${NC} $crate ${CYAN}(${DURATIONS[$crate]}s)${NC}"
                ((PASSED++))
                ;;
              "âœ—") 
                echo -e "${RED}âœ—${NC} $crate ${CYAN}(${DURATIONS[$crate]}s)${NC}"
                ((FAILED++))
                ;;
              "â±") 
                echo -e "${YELLOW}â±${NC} $crate ${CYAN}(${DURATIONS[$crate]}s)${NC}"
                ((TIMEOUT++))
                ;;
              *) 
                echo -e "${YELLOW}âš ${NC} $crate ${CYAN}(${DURATIONS[$crate]}s)${NC}"
                ((SKIP++))
                ;;
            esac
          done
          
          echo ""
          echo -e "${MAGENTA}Results:${NC}"
          echo -e "  ${GREEN}âœ“ Passed:${NC}  $PASSED"
          echo -e "  ${RED}âœ— Failed:${NC}  $FAILED"
          echo -e "  ${YELLOW}â± Timeout:${NC} $TIMEOUT"
          echo -e "  ${YELLOW}âš  Skipped:${NC} $SKIP"
          echo -e "  ${CYAN}â± Total:${NC}   ${TOTAL_DURATION}s"
          echo ""
          
          # Generate markdown summary for GitHub
          cat > /tmp/results.md <<EOF
          ## ðŸ§ª Downstream Compatibility Test Results
          
          **Repository:** \`${REPO_OWNER}/${REPO_NAME}\`  
          **Crate:** \`${CRATE_NAME}\`  
          **Testing:** ${TEST_TYPE}  
          **Ref:** \`${TEST_REF}\`
          
          ### Results
          
          | Crate | Status | Duration |
          |-------|--------|----------|
          EOF
          
          for crate in "${CRATES[@]}"; do
            crate=$(echo "$crate" | xargs)
            [ -z "$crate" ] && continue
            
            status_emoji="${RESULTS[$crate]}"
            status_text=""
            case "$status_emoji" in
              "âœ“") status_text="Passed";;
              "âœ—") status_text="Failed";;
              "â±") status_text="Timeout";;
              *) status_text="Skipped";;
            esac
            
            echo "| \`$crate\` | $status_emoji $status_text | ${DURATIONS[$crate]}s |" >> /tmp/results.md
          done
          
          cat >> /tmp/results.md <<EOF
          
          ### Summary
          
          - âœ“ **Passed:** $PASSED
          - âœ— **Failed:** $FAILED
          - â± **Timeout:** $TIMEOUT
          - âš  **Skipped:** $SKIP
          - â± **Total time:** ${TOTAL_DURATION}s
          
          ---
          <sub>Generated by downstream-test at $(date -u +"%Y-%m-%d %H:%M:%S UTC")</sub>
          EOF
          
          # Save stats for GitHub Actions
          cat > /tmp/stats.env <<EOF
          PASSED=$PASSED
          FAILED=$FAILED
          TIMEOUT=$TIMEOUT
          SKIP=$SKIP
          TOTAL_DURATION=$TOTAL_DURATION
          EOF
          
          cat /tmp/results.md
          
          # Exit with failure if any tests failed
          [ $FAILED -eq 0 ]
          SCRIPT
          
          chmod +x test-all.sh
      
      - name: Run tests in sandbox
        id: test-run
        continue-on-error: true
        run: |
          mkdir -p results
          
          docker run --rm \
            --network none \
            --memory="8g" \
            --cpus="4" \
            --security-opt=no-new-privileges \
            --cap-drop=ALL \
            --pids-limit=200 \
            -v $(pwd):/workspace/crate:ro \
            -v $(pwd)/test-all.sh:/test-all.sh:ro \
            -v $(pwd)/results:/tmp:rw \
            -v downstream-cargo-cache-${{ github.repository_owner }}-${{ github.event.repository.name }}:/usr/local/cargo/registry \
            -v downstream-cargo-git-${{ github.repository_owner }}-${{ github.event.repository.name }}:/usr/local/cargo/git \
            -w /workspace \
            rust:latest \
            bash /test-all.sh \
              "${{ steps.metadata.outputs.crate-name }}" \
              "/workspace/crate" \
              "${{ steps.metadata.outputs.test-type }}" \
              "${{ steps.metadata.outputs.test-ref }}" \
              "${{ steps.metadata.outputs.repo-owner }}" \
              "${{ steps.metadata.outputs.repo-name }}" \
              "${{ steps.config.outputs.crates }}"
      
      - name: Process results
        id: results
        if: always()
        run: |
          if [ -f results/results.md ]; then
            cat results/results.md
            
            # Set multiline output
            {
              echo "markdown<<EOF"
              cat results/results.md
              echo "EOF"
            } >> $GITHUB_OUTPUT
            
            # Load stats
            if [ -f results/stats.env ]; then
              source results/stats.env
              echo "passed=$PASSED" >> $GITHUB_OUTPUT
              echo "failed=$FAILED" >> $GITHUB_OUTPUT
              echo "timeout=$TIMEOUT" >> $GITHUB_OUTPUT
              echo "skip=$SKIP" >> $GITHUB_OUTPUT
              echo "duration=$TOTAL_DURATION" >> $GITHUB_OUTPUT
              
              # Create a summary for the step
              echo "### Test Summary" >> $GITHUB_STEP_SUMMARY
              echo "- âœ“ Passed: $PASSED" >> $GITHUB_STEP_SUMMARY
              echo "- âœ— Failed: $FAILED" >> $GITHUB_STEP_SUMMARY
              echo "- â± Timeout: $TIMEOUT" >> $GITHUB_STEP_SUMMARY
              echo "- âš  Skipped: $SKIP" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "markdown=âŒ Test execution failed - no results generated" >> $GITHUB_OUTPUT
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
          fi
      
      - name: Comment on Pull Request
        if: |
          always() && 
          github.event_name == 'pull_request' &&
          steps.results.outputs.markdown != ''
        uses: actions/github-script@v7
        with:
          script: |
            const markdown = `${{ steps.results.outputs.markdown }}`;
            
            // Try to find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('ðŸ§ª Downstream Compatibility Test Results')
            );
            
            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: markdown
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: markdown
              });
            }
      
      - name: Add to release notes
        if: |
          always() &&
          github.event_name == 'release' &&
          steps.results.outputs.markdown != ''
        uses: actions/github-script@v7
        with:
          script: |
            const markdown = `${{ steps.results.outputs.markdown }}`;
            const release = context.payload.release;
            
            // Append to release body
            const newBody = (release.body || '') + '\n\n' + markdown;
            
            await github.rest.repos.updateRelease({
              owner: context.repo.owner,
              repo: context.repo.repo,
              release_id: release.id,
              body: newBody
            });
      
      - name: Report final status
        if: always()
        run: |
          echo "::notice title=Downstream Tests::Passed: ${{ steps.results.outputs.passed }}, Failed: ${{ steps.results.outputs.failed }}, Timeout: ${{ steps.results.outputs.timeout }}, Skipped: ${{ steps.results.outputs.skip }}"
          
          # Optional: fail the workflow if tests failed
          # Uncomment the next line if you want failures to block merges
          if [ "${{ steps.results.outputs.failed }}" != "0" ]; then exit 1; fi
